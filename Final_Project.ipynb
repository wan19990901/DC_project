{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f5NDXrN2CtH7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIpCl4lKHY8D",
    "outputId": "e0d2c868-376c-446b-e0c2-674c0f4fb0fb"
   },
   "outputs": [],
   "source": [
    "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Industrial_and_Scientific.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb5fGi2wJpXI",
    "outputId": "8942d902-3d6b-4a33-b775-fab14abf6754"
   },
   "outputs": [],
   "source": [
    "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/metaFiles2/meta_Industrial_and_Scientific.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 18.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1; python_version >= \"3\" in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.50.2)\n",
      "Requirement already satisfied: joblib in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.17.0)\n",
      "Requirement already satisfied: regex in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.10.15)\n",
      "Requirement already satisfied: click in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /sfs/qumulo/qhome/ynx9zm/.local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: nltk in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /sfs/qumulo/qhome/ynx9zm/.local/lib/python3.8/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: joblib in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: click in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (from nltk) (4.50.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install pyspark nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddVjvBQ5BnXq"
   },
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "G8Qexuq_3Rx0"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, length, lower, split, when\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"readGZ\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.default.parallelism\", 24) \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 24) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSkWP10AtaKv",
    "outputId": "dcdcffe3-6145-4b91-e530-f0b0eafbffff"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read the gzipped JSON file directly into a DataFrame\n",
    "df = spark.read.json(\"Industrial_and_Scientific.json.gz\")\n",
    "\n",
    "# Show the DataFrame to check if it's loaded correctly\n",
    "#df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7igYuRaV4bF7"
   },
   "outputs": [],
   "source": [
    "### load the meta data\n",
    "\n",
    "df_meta = spark.read.json(\"meta_Industrial_and_Scientific.json.gz\")\n",
    "#df_meta.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfMHyp_wCLIj"
   },
   "source": [
    "## Discussion\n",
    "\n",
    "\n",
    "\n",
    "1.   We can not read some categories (especially those with large data, in this case, the sofrware category) directly in Spark; Need to figure out why and how to solve this. (Tried reading by in raw and use pandas and then spark, but this also failed.)\n",
    "(I skipped this question by choosing another category which is fine to read directly)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lporcTWBqQq"
   },
   "source": [
    "# Data Pre-Processing and visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nulls in asin: 0, Percentage: 0.00%\n",
      "Number of Nulls in image: 1725623, Percentage: 98.14%\n",
      "Number of Nulls in overall: 0, Percentage: 0.00%\n",
      "Number of Nulls in reviewText: 984, Percentage: 0.06%\n",
      "Number of Nulls in reviewTime: 0, Percentage: 0.00%\n",
      "Number of Nulls in reviewerID: 0, Percentage: 0.00%\n",
      "Number of Nulls in reviewerName: 110, Percentage: 0.01%\n",
      "Number of Nulls in style: 1066819, Percentage: 60.67%\n",
      "Number of Nulls in summary: 403, Percentage: 0.02%\n",
      "Number of Nulls in unixReviewTime: 0, Percentage: 0.00%\n",
      "Number of Nulls in verified: 0, Percentage: 0.00%\n",
      "Number of Nulls in vote: 1552025, Percentage: 88.27%\n"
     ]
    }
   ],
   "source": [
    "# summarize the nulls in dataframe\n",
    "for column in df.columns:\n",
    "    # Calculate the number of nulls in the column\n",
    "    null_count = df.filter(col(column).isNull()).count()\n",
    "    \n",
    "    # Calculate the percentage of nulls\n",
    "    null_percentage = (null_count / df.count()) * 100\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Number of Nulls in {column}: {null_count}, Percentage: {null_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LgWrDtZ94w89"
   },
   "outputs": [],
   "source": [
    "# Drop the image, style, vote columns\n",
    "df = df.drop('image', 'style', 'vote')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HoBwuSpS0a_A"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, length, unix_timestamp, to_date\n",
    "\n",
    "# Handling missing values: For simplicity, we'll drop rows with any NULLs\n",
    "df = df.na.drop()\n",
    "\n",
    "# Filtering out unverified reviews\n",
    "df = df.filter(col('verified') == True)\n",
    "\n",
    "# Feature Engineering - creating a new feature for the length of the reviewText\n",
    "df = df.withColumn('reviewText_length', length(col('reviewText')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1635211"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lengths = df.select('reviewText_length').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "AH_C-uRAu5G-",
    "outputId": "90a23133-a2fc-4bb8-83ae-9c0d25fb384a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now convert this list to a Pandas Series\n",
    "pd_series = pd.Series(review_lengths)\n",
    "\n",
    "# Plotting the distribution of reviewText_length using Pandas/Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "pd_series.hist(bins=50)  # Adjust the number of bins for your specific dataset\n",
    "plt.title('Distribution of Review Text Lengths')\n",
    "plt.xlabel('Review Text Length')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LSoJRRFQ2ApP"
   },
   "outputs": [],
   "source": [
    "# Example of filtering based on a condition, such as reviews that are too short/long might be outliers\n",
    "df = df.filter(col('reviewText_length') > 10)  # Example threshold\n",
    "df = df.filter(col('reviewText_length') < 1000)  # Example threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4yIjISgc1xjx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/ynx9zm/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Text Processing - cleaning the review text, undercase the words, tokenizing, and removing stop words (simplified example)\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, FloatType\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Define a UDF for sentiment analysis\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(str(text))\n",
    "    # Classify the polarity of the text\n",
    "    # You can customize this based on your needs\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return \"positive\"\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "    \n",
    "def analyze_sentiment(review_text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = sid.polarity_scores(review_text)['compound']\n",
    "    return sentiment_score\n",
    "\n",
    "sentiment_analysis_udf = udf(analyze_sentiment, FloatType())\n",
    "df = df.withColumn(\"sentiment_score\", sentiment_analysis_udf(df[\"reviewText\"]))\n",
    "\n",
    "\n",
    "\n",
    "# Register the UDF\n",
    "sentiment_udf = udf(get_sentiment, StringType())\n",
    "\n",
    "# Apply sentiment analysis to the 'reviewText' column\n",
    "df = df.withColumn(\"sentiment\", sentiment_udf(\"reviewText\"))\n",
    "\n",
    "\n",
    "df = df.withColumn('reviewText', lower(col('reviewText'))) \n",
    "tokenizer = Tokenizer(inputCol='reviewText', outputCol='reviewText_tokens')\n",
    "df = tokenizer.transform(df)\n",
    "remover = StopWordsRemover(inputCol='reviewText_tokens', outputCol='reviewText_clean')\n",
    "df = remover.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WqZcdGp-5cui"
   },
   "outputs": [],
   "source": [
    "# Split reviewTime into day, month, and year\n",
    "split_col = split(df['reviewTime'], ' ')\n",
    "df = df.withColumn('Day', split_col.getItem(0))\n",
    "df = df.withColumn('Month', split_col.getItem(1).substr(0,2))\n",
    "df = df.withColumn('Year', split_col.getItem(2))\n",
    "df = df.drop('reviewTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCawwLrJ2wv5",
    "outputId": "ab573a2d-74b7-415a-8060-020d234c4853"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695174"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('reviewerName').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdBoW7v721fO",
    "outputId": "92fedbf3-4f68-40c7-9d62-938b99e9bedf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('asin').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IDu-xVsaDMh-"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, count\n",
    "\n",
    "# Average rating\n",
    "average_rating = df.agg(avg(\"overall\")).first()[0]\n",
    "\n",
    "# Count of reviews for each asin\n",
    "reviews_per_asin = df.groupBy(\"asin\").agg(count(\"reviewerID\").alias(\"Number_of_Reviews\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oseS27cytWcg"
   },
   "outputs": [],
   "source": [
    "# Count of reviews for each reviewer\n",
    "reviews_per_reviewers = df.groupBy(\"reviewerID\").agg(count(\"asin\").alias(\"Number_of_Reviews\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6OHclZxHDPTE",
    "outputId": "30222ae8-4009-4309-80bb-1deeae05f1c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 56078)\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/apps/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/apps/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/apps/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py\", line 179, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(111, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnknownException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mconvert_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_instance_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"org.apache.spark.sql.catalyst.parser.ParseException\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mis_instance_of\u001b[0;34m(gateway, java_object, java_class)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     return gateway.jvm.py4j.reflection.TypeUtil.isInstanceOf(\n\u001b[0m\u001b[1;32m    465\u001b[0m         param, java_object)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1664\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} does not exist in the JVM\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_fqn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: py4j.reflection does not exist in the JVM",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1bff73d2a785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert Spark DataFrame to Pandas for Visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mreviews_per_asin_pdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews_per_asin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Histogram for overall ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             pdf = pd.DataFrame.from_records(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \"\"\"\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/traceback_utils.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, tb)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1034\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \"\"\"\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_new_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36m_create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             self.gateway_property, self)\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_to_java_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_thread_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36mconnect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 self.socket = self.ssl_context.wrap_socket(\n\u001b[1;32m    437\u001b[0m                     self.socket, server_hostname=self.java_address)\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "# Convert Spark DataFrame to Pandas for Visualization\n",
    "pdf = df.toPandas()\n",
    "reviews_per_asin_pdf = reviews_per_asin.toPandas()\n",
    "\n",
    "# Histogram for overall ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "pdf['overall'].hist()\n",
    "plt.title('Distribution of Overall Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the pie chart for overall ratings\n",
    "rating_counts = pdf['overall'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(rating_counts, labels=rating_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Overall Ratings')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "MGZpqoW9s-68",
    "outputId": "78848733-cf9f-4212-b896-e66bc0f68c9e"
   },
   "outputs": [],
   "source": [
    "# Bar chart for number of reviews for each asin\n",
    "top_reviews_per_asin_pdf = reviews_per_asin_pdf.sort_values(by='Number_of_Reviews', ascending=False).head(100)\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Set the 'asin' as the index and plot the 'review_count' column\n",
    "top_reviews_per_asin_pdf.set_index('asin')['Number_of_Reviews'].plot(kind='bar', legend=False)\n",
    "plt.title('Number of Reviews for Top 100 ASINs')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('ASIN')\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "ZY61YbgAtiE8",
    "outputId": "b785ec0d-372d-42a2-e900-5f7d0a93b2af"
   },
   "outputs": [],
   "source": [
    "# Bar chart for number of reviews for each reviewers\n",
    "reviews_per_reviewers_pdf = reviews_per_reviewers.toPandas()\n",
    "\n",
    "top_reviews_per_reviewers_pdf = reviews_per_reviewers_pdf.sort_values(by='Number_of_Reviews', ascending=False).head(100)\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Set the 'reviewers' as the index and plot the 'review_count' column\n",
    "top_reviews_per_reviewers_pdf.set_index('reviewerID')['Number_of_Reviews'].plot(kind='bar', legend=False)\n",
    "plt.title('Number of Reviews for Top 100 reviewers')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('reviewers')\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_QVtyi4Ewab"
   },
   "outputs": [],
   "source": [
    "# Convert reviewText and summary columns to a single string\n",
    "review_text_str = ' '.join(df.rdd.map(lambda row: row.reviewText).collect())\n",
    "summary_str = ' '.join(df.rdd.map(lambda row: row.summary).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871
    },
    "id": "0UBh50DFFI1l",
    "outputId": "f5c3b337-fa19-423e-cc2f-b8dffafb8c09"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_word_cloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "generate_word_cloud(review_text_str, \"Word Cloud for Review Text\")\n",
    "generate_word_cloud(summary_str, \"Word Cloud for Summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Az7mi7WwkR5f"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIVXnBAuuVf5"
   },
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15233"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###sampling\n",
    "sampled_df = df.sample(fraction=0.01, seed=42)\n",
    "sampled_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mnzc-mTpuYuj"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Indexing is required to convert string identifiers to numeric indices for the ALS algorithm\n",
    "indexer_user = StringIndexer(inputCol=\"reviewerID\", outputCol=\"userIndex\")\n",
    "df = indexer_user.fit(sampled_df).transform(sampled_df)\n",
    "\n",
    "indexer_item = StringIndexer(inputCol=\"asin\", outputCol=\"itemIndex\")\n",
    "df = indexer_item.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mnzc-mTpuYuj"
   },
   "outputs": [],
   "source": [
    "(train, test) = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csuWnWesuTGB"
   },
   "source": [
    "\n",
    "## ALS\n",
    "\n",
    "refer: https://www.kaggle.com/code/nadianizam/h-m-fashion-recommendation-with-pyspark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "xVGz5N03kT7T"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Setting up the ALS model\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userIndex\", itemCol=\"itemIndex\", ratingCol=\"overall\", coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /sfs/applications/202307/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/site-packages (4.50.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/apps/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ba9ec7562657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the ALS model to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get the number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMaxIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the ALS model to the training data\n",
    "model = als.fit(train)\n",
    "\n",
    "# Get the number of iterations\n",
    "num_iterations = model._java_obj.parent().getMaxIter()\n",
    "\n",
    "# Create an RMSE evaluator using the label and predicted columns\n",
    "reg_evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"overall\", predictionCol=\"prediction\")\n",
    "\n",
    "# Create tqdm wrapper for the range of iterations\n",
    "for epoch in tqdm(range(num_iterations), desc=\"Training ALS Model\"):\n",
    "    # Train the model for one iteration (you may need to adjust this depending on your needs)\n",
    "    model._java_obj.parent().setNumBlocks(10).setMaxIter(epoch + 1)\n",
    "    model = als.fit(train)\n",
    "\n",
    "    # Predict on the train and test sets\n",
    "    predictions_train = model.transform(train)\n",
    "    predictions_test = model.transform(test)\n",
    "\n",
    "    # Evaluate the model on training data\n",
    "    rmse_train = reg_evaluator.evaluate(predictions_train)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    rmse_test = reg_evaluator.evaluate(predictions_test)\n",
    "\n",
    "    # Optionally print or log the RMSE values for each iteration\n",
    "    print(f\"Iteration {epoch + 1}: RMSE (Train) = {rmse_train:.4f}, RMSE (Test) = {rmse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xVGz5N03kT7T"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/apps/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9b3c0d62101d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fitting the ALS model on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Predicting on the train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/core/anaconda/2020.11-py3.8/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fitting the ALS model on the training data\n",
    "model = als.fit(train)\n",
    "\n",
    "# Predicting on the train and test sets\n",
    "predictions_train = model.transform(train)\n",
    "predictions_test = model.transform(test)\n",
    "\n",
    "# Create an RMSE evaluator using the label and predicted columns\n",
    "reg_evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"overall\", predictionCol=\"prediction\")\n",
    "\n",
    "# Evaluate the model on training data\n",
    "rmse_train = reg_evaluator.evaluate(predictions_train)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "rmse_test = reg_evaluator.evaluate(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xVGz5N03kT7T"
   },
   "outputs": [],
   "source": [
    "#grid search for ALS model\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20, 30]) \\\n",
    "    .addGrid(als.maxIter, [5, 10, 15]) \\\n",
    "    .addGrid(als.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "\n",
    "##cross validation\n",
    "cross_val = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cross_val.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cv_model.bestModel\n",
    "best_model.save(\"models/Best_RatingALSModel.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recommendForAllUsers(10).show(1, truncate = False)\n",
    "model.save(\"models/RatingALSModel.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIkh4pJbkT-_",
    "outputId": "89a85da8-d6a6-42b0-ef0d-56e42861934e"
   },
   "outputs": [],
   "source": [
    "rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4t13CqrkUCj",
    "outputId": "2443eee2-ea8b-4fc4-bb72-18ff59e75711"
   },
   "outputs": [],
   "source": [
    "rmse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "recommendnum = 10\n",
    "als_model = ALSModel.load(\"models/RatingALSModel.obj\")\n",
    "als_model.recommendForAllUsers(recommendnum).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.groupBy(\"userIndex\").count().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.filter(train['userIndex'] == testUserID).select('itemIndex').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.select('userIndex').show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_temp = als_model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df_temp.select('recommendations').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,explode\n",
    "df_temp0 = df_temp.withColumn(\"name\", explode(col('recommendations')))\n",
    "df_temp0.withColumn(\"name2\", col('name').getItem(0)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,expr\n",
    "df_temp0 = df_temp.withColumn(\"name\", expr(\"transform(recommendations, r -> r.itemIndex)\"))\n",
    "df_temp0.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.filter(train['userIndex'] == m.userIndex).select('itemIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "actualitem = train.groupby('userIndex').agg(collect_list('itemIndex').alias('indexlist'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = df_temp0.join(actualitem, 'userIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_intersect, size, avg\n",
    "metrics = result.withColumn('TP', size(array_intersect(col('name'),col('indexlist')))) \\\n",
    "                .withColumn('precision', col('TP')/recommendnum) \\\n",
    "                .withColumn('recall', col('TP')/size(col('indexlist'))) \\\n",
    "                .withColumn('F1', when((col('precision') + col('recall')) >0,\n",
    "                                        2* (col('precision') *col('recall'))/(col('precision') +col('recall')))\n",
    "                             .otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max as ma\n",
    "average_metrics = metrics.agg(\n",
    "    ma(col('precision')),\n",
    "    ma(col('recall')),\n",
    "    ma(col('F1'))\n",
    ")\n",
    "average_metrics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp0.withColumn(\"name2\", col('name').getItem(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in als_model.userFactors.select(\"id\").collect():\n",
    "    userId = r.id\n",
    "    cateId_df = pd.DataFrame(pdf.cateId,unique(),columns=['cateId'])\n",
    "    cateId_df.insert(0,'userId',np.array([userId for i in range(6769)]))\n",
    "\n",
    "    ret = set()\n",
    "    # 利用模型，传入datasets(userId, cateId)，这里控制了userId一样，所以相当于是在求某用户对所有分类的兴趣程度\n",
    "    cateId_list = als_model.transform(spark.createDataFrame(cateId_df)).sort('prediction',ascending=False).na.drop()\n",
    "   \n",
    "    # 从前20个分类中选出500个进行召回\n",
    "    for i in cateId_list.head(20):\n",
    "        need = 500 - len(ret)    # 如果不足500个，那么随机选出need个广告\n",
    "        ret = ret.union(np.random.choice(pdf.where(pdf.cateId==i.cateId).adgroupId.dropna().astype(np.int64),need))\n",
    "        if len(ret) >= 500:    # 如果达到500个则退出\n",
    "            break\n",
    "    client.sadd(userId, *ret)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeLO7apex1pt"
   },
   "source": [
    "## GraphFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WrR_GanHyVEe",
    "outputId": "5d8a705f-e9c2-417b-f96f-9819e55a8c76"
   },
   "outputs": [],
   "source": [
    "!pip install graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uEIXzWg_wvOG",
    "outputId": "a924f54d-81f5-4b0c-acb4-03769b48bc40"
   },
   "outputs": [],
   "source": [
    "from graphframes import GraphFrame\n",
    "\n",
    "# Assuming 'df' is your original PySpark DataFrame and it has been indexed\n",
    "# Create vertices DataFrame\n",
    "vertices = df.selectExpr(\"userIndex as id\").distinct().union(df.selectExpr(\"itemIndex as id\").distinct()) # check if those two index overlap\n",
    "\n",
    "# Create edges DataFrame\n",
    "edges = df.selectExpr(\"userIndex as src\", \"itemIndex as dst\", \"overall as rating\")\n",
    "\n",
    "# Create a GraphFrame\n",
    "graph = GraphFrame(vertices, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzjaV0l0yTCw"
   },
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# 1: Hyperparameter tuning\n",
    "# 2: How to make use of the graph functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5euM0Dd21S6-"
   },
   "source": [
    "# Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"item总数：\", df_meta.groupBy(\"asin\").count().count())\n",
    "print(\"brand总数：\", df_meta.groupBy(\"brand\").count().count())\n",
    "print(\"category总数：\", df_meta.groupBy(\"category\").count().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"分类特征值个数情况: \")\n",
    "print(\"cms_segid: \", user_profile_df.groupBy(\"cms_segid\").count().count())\n",
    "print(\"cms_group_id: \", user_profile_df.groupBy(\"cms_group_id\").count().count())\n",
    "print(\"final_gender_code: \", user_profile_df.groupBy(\"final_gender_code\").count().count())\n",
    "print(\"age_level: \", user_profile_df.groupBy(\"age_level\").count().count())\n",
    "print(\"shopping_level: \", user_profile_df.groupBy(\"shopping_level\").count().count())\n",
    "print(\"occupation: \", user_profile_df.groupBy(\"occupation\").count().count())\n",
    "\n",
    "print(\"含缺失值的特征情况: \")\n",
    "df_meta.groupBy(\"details\").count().show()\n",
    "df_meta.groupBy(\"feature\").count().show()\n",
    "df_meta.groupBy(\"fit\").count().show()\n",
    "\n",
    "t_count = df_meta.count()\n",
    "\n",
    "pl_na_count = t_count - user_profile_df.dropna(subset=[\"pvalue_level\"]).count()\n",
    "print(\"pvalue_level的空值情况：\", pl_na_count, \"空值占比：%0.2f%%\"%(pl_na_count/t_count*100))\n",
    "\n",
    "nul_na_count = t_count - user_profile_df.dropna(subset=[\"new_user_class_level\"]).count()\n",
    "print(\"new_user_class_level的空值情况：\", nul_na_count, \"空值占比：%0.2f%%\"%(nul_na_count/t_count*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ynx9zm/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "print(\"含缺失值的特征情况: \")\n",
    "df_meta.groupBy(\"details\").count().show()\n",
    "df_meta.groupBy(\"feature\").count().show()\n",
    "df_meta.groupBy(\"fit\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
